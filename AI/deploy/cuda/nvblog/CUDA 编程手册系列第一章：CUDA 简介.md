![](https://developer-blogs.nvidia.com/zh-cn-blog/wp-content/uploads/sites/2/2022/04/CUDA-toolkit-featured.png)

本项目为CUDA官方手册的中文翻译版，有个人翻译并添加自己的理解。主要介绍CUDA编程模型和接口。

## 1.1 我们为什么要使用GPU

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#gpugraphics-processing-unit%E5%9C%A8%E7%9B%B8%E5%90%8C%E7%9A%84%E4%BB%B7%E6%A0%BC%E5%92%8C%E5%8A%9F%E7%8E%87%E8%8C%83%E5%9B%B4%E5%86%85%E6%AF%94cpu%E6%8F%90%E4%BE%9B%E6%9B%B4%E9%AB%98%E7%9A%84%E6%8C%87%E4%BB%A4%E5%90%9E%E5%90%90%E9%87%8F%E5%92%8C%E5%86%85%E5%AD%98%E5%B8%A6%E5%AE%BD%E8%AE%B8%E5%A4%9A%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%88%A9%E7%94%A8%E8%BF%99%E4%BA%9B%E6%9B%B4%E9%AB%98%E7%9A%84%E8%83%BD%E5%8A%9B%E5%9C%A8gpu%E4%B8%8A%E6%AF%94%E5%9C%A8cpu%E4%B8%8A%E8%BF%90%E8%A1%8C%E5%BE%97%E6%9B%B4%E5%BF%AB%E5%8F%82%E8%A7%81gpu%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%85%B6%E4%BB%96%E8%AE%A1%E7%AE%97%E8%AE%BE%E5%A4%87%E5%A6%82fpga%E4%B9%9F%E9%9D%9E%E5%B8%B8%E8%8A%82%E8%83%BD%E4%BD%86%E6%8F%90%E4%BE%9B%E7%9A%84%E7%BC%96%E7%A8%8B%E7%81%B5%E6%B4%BB%E6%80%A7%E8%A6%81%E6%AF%94gpu%E5%B0%91%E5%BE%97%E5%A4%9A)GPU（Graphics Processing Unit）在相同的价格和功率范围内，比CPU提供更高的指令吞吐量和内存带宽。许多应用程序利用这些更高的能力，在GPU上比在CPU上运行得更快(参见[GPU应用程序](https://www.nvidia.com/object/gpu-applications.html))。其他计算设备，如FPGA，也非常节能，但提供的编程灵活性要比GPU少得多。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#gpu%E5%92%8Ccpu%E5%9C%A8%E5%8A%9F%E8%83%BD%E4%B8%8A%E7%9A%84%E5%B7%AE%E5%BC%82%E6%98%AF%E5%9B%A0%E4%B8%BA%E5%AE%83%E4%BB%AC%E7%9A%84%E8%AE%BE%E8%AE%A1%E7%9B%AE%E6%A0%87%E4%B8%8D%E5%90%8C%E8%99%BD%E7%84%B6-cpu-%E6%97%A8%E5%9C%A8%E4%BB%A5%E5%B0%BD%E5%8F%AF%E8%83%BD%E5%BF%AB%E7%9A%84%E9%80%9F%E5%BA%A6%E6%89%A7%E8%A1%8C%E4%B8%80%E7%B3%BB%E5%88%97%E7%A7%B0%E4%B8%BA%E7%BA%BF%E7%A8%8B%E7%9A%84%E6%93%8D%E4%BD%9C%E5%B9%B6%E4%B8%94%E5%8F%AF%E4%BB%A5%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C%E6%95%B0%E5%8D%81%E4%B8%AA%E8%BF%99%E6%A0%B7%E7%9A%84%E7%BA%BF%E7%A8%8B%E4%BD%86gpu%E5%8D%B4%E8%83%BD%E5%B9%B6%E8%A1%8C%E6%89%A7%E8%A1%8C%E6%88%90%E5%8D%83%E4%B8%8A%E4%B8%87%E4%B8%AA%E6%91%8A%E9%94%80%E8%BE%83%E6%85%A2%E7%9A%84%E5%8D%95%E7%BA%BF%E7%A8%8B%E6%80%A7%E8%83%BD%E4%BB%A5%E5%AE%9E%E7%8E%B0%E6%9B%B4%E5%A4%A7%E7%9A%84%E5%90%9E%E5%90%90%E9%87%8F)GPU和CPU在功能上的差异是因为它们的设计目标不同。虽然 CPU 旨在以尽可能快的速度执行一系列称为线程的操作，并且可以并行执行数十个这样的线程。但GPU却能并行执行成千上万个(摊销较慢的单线程性能以实现更大的吞吐量)。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#gpu-%E4%B8%93%E9%97%A8%E7%94%A8%E4%BA%8E%E9%AB%98%E5%BA%A6%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%9B%A0%E6%AD%A4%E8%AE%BE%E8%AE%A1%E6%97%B6%E6%9B%B4%E5%A4%9A%E7%9A%84%E6%99%B6%E4%BD%93%E7%AE%A1%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E8%80%8C%E4%B8%8D%E6%98%AF%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E5%92%8C%E6%B5%81%E9%87%8F%E6%8E%A7%E5%88%B6)GPU 专门用于高度并行计算，因此设计时更多的晶体管用于数据处理，而不是数据缓存和流量控制。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E4%B8%8B%E5%9B%BE%E6%98%BE%E7%A4%BA%E4%BA%86-cpu-%E4%B8%8E-gpu-%E7%9A%84%E8%8A%AF%E7%89%87%E8%B5%84%E6%BA%90%E5%88%86%E5%B8%83%E7%A4%BA%E4%BE%8B)下图显示了 CPU 与 GPU 的芯片资源分布示例。

![](https://developer-blogs.nvidia.com/zh-cn-blog/wp-content/uploads/sites/2/2022/04/gpu-devotes-more-transistors-to-data-processing-1024x506.png)

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E5%B0%86%E6%9B%B4%E5%A4%9A%E6%99%B6%E4%BD%93%E7%AE%A1%E7%94%A8%E4%BA%8E%E6%95%B0%E6%8D%AE%E5%A4%84%E7%90%86%E4%BE%8B%E5%A6%82%E6%B5%AE%E7%82%B9%E8%AE%A1%E7%AE%97%E6%9C%89%E5%88%A9%E4%BA%8E%E9%AB%98%E5%BA%A6%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97gpu%E5%8F%AF%E4%BB%A5%E9%80%9A%E8%BF%87%E8%AE%A1%E7%AE%97%E9%9A%90%E8%97%8F%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%BB%B6%E8%BF%9F%E8%80%8C%E4%B8%8D%E6%98%AF%E4%BE%9D%E9%9D%A0%E5%A4%A7%E6%95%B0%E6%8D%AE%E7%BC%93%E5%AD%98%E5%92%8C%E5%A4%8D%E6%9D%82%E7%9A%84%E6%B5%81%E6%8E%A7%E5%88%B6%E6%9D%A5%E9%81%BF%E5%85%8D%E9%95%BF%E6%97%B6%E9%97%B4%E7%9A%84%E5%86%85%E5%AD%98%E8%AE%BF%E9%97%AE%E5%BB%B6%E8%BF%9F%E8%BF%99%E4%B8%A4%E8%80%85%E5%9C%A8%E6%99%B6%E4%BD%93%E7%AE%A1%E6%96%B9%E9%9D%A2%E9%83%BD%E6%98%AF%E6%98%82%E8%B4%B5%E7%9A%84)将更多晶体管用于数据处理，例如浮点计算，有利于高度并行计算。GPU可以通过计算隐藏内存访问延迟，而不是依靠大数据缓存和复杂的流控制来避免长时间的内存访问延迟，这两者在晶体管方面都是昂贵的。

## [](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#12-cuda%E9%80%9A%E7%94%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E5%92%8C%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B)1.2 CUDA®：通用并行计算平台和编程模型

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#2006-%E5%B9%B4-11-%E6%9C%88nvidia-%E6%8E%A8%E5%87%BA%E4%BA%86-cuda%E8%BF%99%E6%98%AF%E4%B8%80%E7%A7%8D%E9%80%9A%E7%94%A8%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%B9%B3%E5%8F%B0%E5%92%8C%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%AE%83%E5%88%A9%E7%94%A8-nvidia-gpu-%E4%B8%AD%E7%9A%84%E5%B9%B6%E8%A1%8C%E8%AE%A1%E7%AE%97%E5%BC%95%E6%93%8E%E4%BB%A5%E6%AF%94-cpu-%E6%9B%B4%E6%9C%89%E6%95%88%E7%9A%84%E6%96%B9%E5%BC%8F%E8%A7%A3%E5%86%B3%E8%AE%B8%E5%A4%9A%E5%A4%8D%E6%9D%82%E7%9A%84%E8%AE%A1%E7%AE%97%E9%97%AE%E9%A2%98)2006 年 11 月，NVIDIA® 推出了 CUDA®，这是一种通用并行计算平台和编程模型，它利用 NVIDIA GPU 中的并行计算引擎以比 CPU 更有效的方式解决许多复杂的计算问题。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#cuda-%E9%99%84%E5%B8%A6%E4%B8%80%E4%B8%AA%E8%BD%AF%E4%BB%B6%E7%8E%AF%E5%A2%83%E5%85%81%E8%AE%B8%E5%BC%80%E5%8F%91%E4%BA%BA%E5%91%98%E4%BD%BF%E7%94%A8-c-%E4%BD%9C%E4%B8%BA%E9%AB%98%E7%BA%A7%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80-%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%E6%94%AF%E6%8C%81%E5%85%B6%E4%BB%96%E8%AF%AD%E8%A8%80%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E7%BC%96%E7%A8%8B%E6%8E%A5%E5%8F%A3%E6%88%96%E5%9F%BA%E4%BA%8E%E6%8C%87%E4%BB%A4%E7%9A%84%E6%96%B9%E6%B3%95%E4%BE%8B%E5%A6%82-fortrandirectcomputeopenacc)CUDA 附带一个软件环境，允许开发人员使用 C++ 作为高级编程语言。 如下图所示，支持其他语言、应用程序编程接口或基于指令的方法，例如 FORTRAN、DirectCompute、OpenACC。

![](https://developer-blogs.nvidia.com/zh-cn-blog/wp-content/uploads/sites/2/2022/04/gpu-computing-applications.png)

## [](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#13-%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B)1.3 可扩展的编程模型

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E5%A4%9A%E6%A0%B8-cpu-%E5%92%8C%E4%BC%97%E6%A0%B8-gpu-%E7%9A%84%E5%87%BA%E7%8E%B0%E6%84%8F%E5%91%B3%E7%9D%80%E4%B8%BB%E6%B5%81%E5%A4%84%E7%90%86%E5%99%A8%E8%8A%AF%E7%89%87%E7%8E%B0%E5%9C%A8%E6%98%AF%E5%B9%B6%E8%A1%8C%E7%B3%BB%E7%BB%9F%E6%8C%91%E6%88%98%E5%9C%A8%E4%BA%8E%E5%BC%80%E5%8F%91%E8%83%BD%E5%A4%9F%E9%80%8F%E6%98%8E%E5%9C%B0%E6%89%A9%E5%B1%95%E5%8F%AF%E5%B9%B6%E8%A1%8C%E7%9A%84%E5%BA%94%E7%94%A8%E8%BD%AF%E4%BB%B6%E6%9D%A5%E5%88%A9%E7%94%A8%E4%B8%8D%E6%96%AD%E5%A2%9E%E5%8A%A0%E7%9A%84%E5%A4%84%E7%90%86%E5%99%A8%E5%86%85%E6%A0%B8%E6%95%B0%E9%87%8F%E5%B0%B1%E5%83%8F-3d-%E5%9B%BE%E5%BD%A2%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E9%80%8F%E6%98%8E%E5%9C%B0%E5%B0%86%E5%85%B6%E5%B9%B6%E8%A1%8C%E6%80%A7%E6%89%A9%E5%B1%95%E5%88%B0%E5%85%B7%E6%9C%89%E5%B9%BF%E6%B3%9B%E4%B8%8D%E5%90%8C%E5%86%85%E6%A0%B8%E6%95%B0%E9%87%8F%E7%9A%84%E5%A4%9A%E6%A0%B8-gpu-%E4%B8%80%E6%A0%B7)多核 CPU 和众核 GPU 的出现意味着主流处理器芯片现在是并行系统。挑战在于开发能够透明地扩展可并行的应用软件，来利用不断增加的处理器内核数量。就像 3D 图形应用程序透明地将其并行性扩展到具有广泛不同内核数量的多核 GPU 一样。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#cuda-%E5%B9%B6%E8%A1%8C%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E6%97%A8%E5%9C%A8%E5%85%8B%E6%9C%8D%E8%BF%99%E4%B8%80%E6%8C%91%E6%88%98%E5%90%8C%E6%97%B6%E4%B8%BA%E7%86%9F%E6%82%89-c-%E7%AD%89%E6%A0%87%E5%87%86%E7%BC%96%E7%A8%8B%E8%AF%AD%E8%A8%80%E7%9A%84%E7%A8%8B%E5%BA%8F%E5%91%98%E4%BF%9D%E6%8C%81%E8%BE%83%E4%BD%8E%E7%9A%84%E5%AD%A6%E4%B9%A0%E6%9B%B2%E7%BA%BF)CUDA 并行编程模型旨在克服这一挑战，同时为熟悉 C 等标准编程语言的程序员保持较低的学习曲线。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E5%85%B6%E6%A0%B8%E5%BF%83%E6%98%AF%E4%B8%89%E4%B8%AA%E5%85%B3%E9%94%AE%E6%8A%BD%E8%B1%A1%E7%BA%BF%E7%A8%8B%E7%BB%84%E7%9A%84%E5%B1%82%E6%AC%A1%E7%BB%93%E6%9E%84%E5%85%B1%E4%BA%AB%E5%86%85%E5%AD%98%E5%92%8C%E5%B1%8F%E9%9A%9C%E5%90%8C%E6%AD%A5%E5%AE%83%E4%BB%AC%E5%8F%AA%E6%98%AF%E4%BD%9C%E4%B8%BA%E6%9C%80%E5%B0%8F%E7%9A%84%E8%AF%AD%E8%A8%80%E6%89%A9%E5%B1%95%E9%9B%86%E5%90%91%E7%A8%8B%E5%BA%8F%E5%91%98%E5%85%AC%E5%BC%80)其核心是三个关键抽象——线程组的层次结构、共享内存和屏障同步——它们只是作为最小的语言扩展集向程序员公开。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E8%BF%99%E4%BA%9B%E6%8A%BD%E8%B1%A1%E6%8F%90%E4%BE%9B%E4%BA%86%E7%BB%86%E7%B2%92%E5%BA%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%92%8C%E7%BA%BF%E7%A8%8B%E5%B9%B6%E8%A1%8C%E5%B5%8C%E5%A5%97%E5%9C%A8%E7%B2%97%E7%B2%92%E5%BA%A6%E7%9A%84%E6%95%B0%E6%8D%AE%E5%B9%B6%E8%A1%8C%E5%92%8C%E4%BB%BB%E5%8A%A1%E5%B9%B6%E8%A1%8C%E4%B8%AD%E5%AE%83%E4%BB%AC%E6%8C%87%E5%AF%BC%E7%A8%8B%E5%BA%8F%E5%91%98%E5%B0%86%E9%97%AE%E9%A2%98%E5%88%92%E5%88%86%E4%B8%BA%E5%8F%AF%E4%BB%A5%E7%94%B1%E7%BA%BF%E7%A8%8B%E5%9D%97%E5%B9%B6%E8%A1%8C%E7%8B%AC%E7%AB%8B%E8%A7%A3%E5%86%B3%E7%9A%84%E7%B2%97%E7%95%A5%E5%AD%90%E9%97%AE%E9%A2%98%E5%B9%B6%E5%B0%86%E6%AF%8F%E4%B8%AA%E5%AD%90%E9%97%AE%E9%A2%98%E5%88%92%E5%88%86%E4%B8%BA%E5%8F%AF%E4%BB%A5%E7%94%B1%E5%9D%97%E5%86%85%E6%89%80%E6%9C%89%E7%BA%BF%E7%A8%8B%E5%B9%B6%E8%A1%8C%E5%8D%8F%E4%BD%9C%E8%A7%A3%E5%86%B3%E7%9A%84%E6%9B%B4%E7%B2%BE%E7%BB%86%E7%9A%84%E9%83%A8%E5%88%86)这些抽象提供了细粒度的数据并行和线程并行，嵌套在粗粒度的数据并行和任务并行中。它们指导程序员将问题划分为可以由线程块并行独立解决的粗略子问题，并将每个子问题划分为可以由块内所有线程并行协作解决的更精细的部分。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E8%BF%99%E7%A7%8D%E5%88%86%E8%A7%A3%E9%80%9A%E8%BF%87%E5%85%81%E8%AE%B8%E7%BA%BF%E7%A8%8B%E5%9C%A8%E8%A7%A3%E5%86%B3%E6%AF%8F%E4%B8%AA%E5%AD%90%E9%97%AE%E9%A2%98%E6%97%B6%E8%BF%9B%E8%A1%8C%E5%8D%8F%E4%BD%9C%E6%9D%A5%E4%BF%9D%E7%95%99%E8%AF%AD%E8%A8%80%E8%A1%A8%E8%BE%BE%E8%83%BD%E5%8A%9B%E5%90%8C%E6%97%B6%E5%AE%9E%E7%8E%B0%E8%87%AA%E5%8A%A8%E5%8F%AF%E6%89%A9%E5%B1%95%E6%80%A7%E5%AE%9E%E9%99%85%E4%B8%8A%E6%AF%8F%E4%B8%AA%E7%BA%BF%E7%A8%8B%E5%9D%97%E9%83%BD%E5%8F%AF%E4%BB%A5%E5%9C%A8-gpu-%E5%86%85%E7%9A%84%E4%BB%BB%E4%BD%95%E5%8F%AF%E7%94%A8multiprocessor%E4%B8%8A%E4%BB%A5%E4%B9%B1%E5%BA%8F%E5%B9%B6%E5%8F%91%E6%88%96%E9%A1%BA%E5%BA%8F%E8%B0%83%E5%BA%A6%E4%BB%A5%E4%BE%BF%E7%BC%96%E8%AF%91%E7%9A%84-cuda-%E7%A8%8B%E5%BA%8F%E5%8F%AF%E4%BB%A5%E5%9C%A8%E4%BB%BB%E6%84%8F%E6%95%B0%E9%87%8F%E7%9A%84%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E4%B8%8A%E6%89%A7%E8%A1%8C%E5%A6%82%E4%B8%8B%E5%9B%BE%E6%89%80%E7%A4%BA%E5%B9%B6%E4%B8%94%E5%8F%AA%E6%9C%89%E8%BF%90%E8%A1%8C%E6%97%B6%E7%B3%BB%E7%BB%9F%E9%9C%80%E8%A6%81%E7%9F%A5%E9%81%93%E7%89%A9%E7%90%86multiprocessor%E4%B8%AA%E6%95%B0)这种分解通过允许线程在解决每个子问题时进行协作来保留语言表达能力，同时实现自动可扩展性。实际上，每个线程块都可以在 GPU 内的任何可用multiprocessor上以乱序、并发或顺序调度，以便编译的 CUDA 程序可以在任意数量的多处理器上执行，如下图所示，并且只有运行时系统需要知道物理multiprocessor个数。

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E8%BF%99%E7%A7%8D%E5%8F%AF%E6%89%A9%E5%B1%95%E7%9A%84%E7%BC%96%E7%A8%8B%E6%A8%A1%E5%9E%8B%E5%85%81%E8%AE%B8-gpu-%E6%9E%B6%E6%9E%84%E9%80%9A%E8%BF%87%E7%AE%80%E5%8D%95%E5%9C%B0%E6%89%A9%E5%B1%95multiprocessor%E5%92%8C%E5%86%85%E5%AD%98%E5%88%86%E5%8C%BA%E7%9A%84%E6%95%B0%E9%87%8F%E6%9D%A5%E8%B7%A8%E8%B6%8A%E5%B9%BF%E6%B3%9B%E7%9A%84%E5%B8%82%E5%9C%BA%E8%8C%83%E5%9B%B4%E9%AB%98%E6%80%A7%E8%83%BD%E5%8F%91%E7%83%A7%E5%8F%8B-geforce-gpu-%E4%B8%93%E4%B8%9A%E7%9A%84-quadro-%E5%92%8C-tesla-%E8%AE%A1%E7%AE%97%E4%BA%A7%E5%93%81-%E6%9C%89%E5%85%B3%E6%89%80%E6%9C%89%E6%94%AF%E6%8C%81-cuda-%E7%9A%84-gpu-%E7%9A%84%E5%88%97%E8%A1%A8%E8%AF%B7%E5%8F%82%E9%98%85%E6%94%AF%E6%8C%81-cuda-%E7%9A%84-gpu)这种可扩展的编程模型允许 GPU 架构通过简单地扩展multiprocessor和内存分区的数量来跨越广泛的市场范围：高性能发烧友 GeForce GPU ，专业的 Quadro 和 Tesla 计算产品 (有关所有支持 CUDA 的 GPU 的列表，请参阅[支持 CUDA 的 GPU](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#cuda-enabled-gpus)）。

![](https://developer-blogs.nvidia.com/zh-cn-blog/wp-content/uploads/sites/2/2022/04/automatic-scalability-1.png)

[](https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese/blob/main/%E7%AC%AC1%E7%AB%A0CUDA%E7%AE%80%E4%BB%8B/%E7%AC%AC%E4%B8%80%E7%AB%A0-CUDA%E7%AE%80%E4%BB%8B.md#%E6%B3%A8%E6%84%8Fgpu-%E6%98%AF%E5%9B%B4%E7%BB%95%E4%B8%80%E7%B3%BB%E5%88%97%E6%B5%81%E5%BC%8F%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8-sm-streaming-multiprocessors-%E6%9E%84%E5%BB%BA%E7%9A%84%E6%9C%89%E5%85%B3%E8%AF%A6%E7%BB%86%E4%BF%A1%E6%81%AF%E8%AF%B7%E5%8F%82%E9%98%85%E7%A1%AC%E4%BB%B6%E5%AE%9E%E7%8E%B0-%E5%A4%9A%E7%BA%BF%E7%A8%8B%E7%A8%8B%E5%BA%8F%E8%A2%AB%E5%88%92%E5%88%86%E4%B8%BA%E5%BD%BC%E6%AD%A4%E7%8B%AC%E7%AB%8B%E6%89%A7%E8%A1%8C%E7%9A%84%E7%BA%BF%E7%A8%8B%E5%9D%97%E5%9B%A0%E6%AD%A4%E5%85%B7%E6%9C%89%E6%9B%B4%E5%A4%9Amultiprocessor%E7%9A%84-gpu-%E5%B0%86%E6%AF%94%E5%85%B7%E6%9C%89%E6%9B%B4%E5%B0%91%E5%A4%9A%E5%A4%84%E7%90%86%E5%99%A8%E7%9A%84-gpu-%E5%9C%A8%E6%9B%B4%E7%9F%AD%E7%9A%84%E6%97%B6%E9%97%B4%E5%86%85%E5%AE%8C%E6%88%90%E7%A8%8B%E5%BA%8F%E6%89%A7%E8%A1%8C)**注意：**GPU 是围绕一系列流式多处理器 (SM: Streaming Multiprocessors) 构建的（有关详细信息，请参[阅硬件实现](https://docs.nvidia.com/cuda/cuda-c-programming-guide/index.html#hardware-implementation)）。 多线程程序被划分为彼此独立执行的线程块，因此具有更多multiprocessor的 GPU 将比具有更少多处理器的 GPU 在更短的时间内完成程序执行。

## 关于作者